{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What drives the price of a car?\n",
    "\n",
    "![](images/kurt.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OVERVIEW**\n",
    "\n",
    "In this application, you will explore a dataset from kaggle. The original dataset contained information on 3 million used cars. The provided dataset contains information on 426K cars to ensure speed of processing.  Your goal is to understand what factors make a car more or less expensive.  As a result of your analysis, you should provide clear recommendations to your client -- a used car dealership -- as to what consumers value in a used car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRISP-DM Framework\n",
    "\n",
    "<center>\n",
    "    <img src = images/crisp.png width = 50%/>\n",
    "</center>\n",
    "\n",
    "\n",
    "To frame the task, throughout our practical applications we will refer back to a standard process in industry for data projects called CRISP-DM.  This process provides a framework for working through a data problem.  Your first step in this application will be to read through a brief overview of CRISP-DM [here](https://mo-pcco.s3.us-east-1.amazonaws.com/BH-PCMLAI/module_11/readings_starter.zip).  After reading the overview, answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "From a business perspective, we are tasked with identifying key drivers for used car prices.  In the CRISP-DM overview, we are asked to convert this business framing to a data problem definition.  Using a few sentences, reframe the task as a data task with the appropriate technical vocabulary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Answer\n",
    "## Predicting the price of the car based on features and attributes. The used car dealership is looking for what features/data points in the histhistorocal data drive the proce of a used car. We could look at this as what data points from the data set can be more benificial to predicting the price of a used car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "After considering the business understanding, we want to get familiar with our data.  Write down some steps that you would take to get to know the dataset and identify any quality issues within.  Take time to get to know the dataset and explore what information it contains and how this could be used to inform your business understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some steps which we would need to take for the data undersatnding are as \n",
    "###    1. Collect the data \n",
    "###    2. Describe the data \n",
    "### 3. Explore the data \n",
    "### 4. Verify data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collection and Loading of Data to Data Frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:15.470095Z",
     "start_time": "2024-03-13T00:29:14.573675Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df= pd.read_csv('data/vehicles.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:17.087887Z",
     "start_time": "2024-03-13T00:29:17.080961Z"
    }
   },
   "outputs": [],
   "source": [
    "df.tail(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:17.115217Z",
     "start_time": "2024-03-13T00:29:17.109532Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data checkes \n",
    "### Missing values Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:17.557555Z",
     "start_time": "2024-03-13T00:29:17.193521Z"
    }
   },
   "outputs": [],
   "source": [
    "null_counts = df.isnull().sum()\n",
    "total_rows = len(df)\n",
    "null_percentages = (null_counts / total_rows) * 100\n",
    "\n",
    "# Print the result\n",
    "print(null_percentages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us explore the Condition column a bit to understand what to do with the null Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:17.568035Z",
     "start_time": "2024-03-13T00:29:17.558464Z"
    }
   },
   "outputs": [],
   "source": [
    "df['condition'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will replace NaN with good as this is the most common value in the data set and in real world since this is a used car we can consider it as good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:19.307622Z",
     "start_time": "2024-03-13T00:29:19.264356Z"
    }
   },
   "outputs": [],
   "source": [
    "df['condition'] = df['condition'].fillna('good')\n",
    "df['condition'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the missing values in cylinder column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:19.319292Z",
     "start_time": "2024-03-13T00:29:19.309449Z"
    }
   },
   "outputs": [],
   "source": [
    "df['cylinders'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:21.374418Z",
     "start_time": "2024-03-13T00:29:21.362648Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#df['cylinders'].fillna('6 cylinders',inplace=True )\n",
    "#df['cylinders'].value_counts(dropna=False)\n",
    "df['cylinders'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us fill the NaN value with most popular value of 6 cylinders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:21.412287Z",
     "start_time": "2024-03-13T00:29:21.397400Z"
    }
   },
   "outputs": [],
   "source": [
    "df['cylinders'].fillna('6 cylinders', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:21.479417Z",
     "start_time": "2024-03-13T00:29:21.468989Z"
    }
   },
   "outputs": [],
   "source": [
    "df['cylinders'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Vin and ID as it is a unique identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:21.536429Z",
     "start_time": "2024-03-13T00:29:21.506643Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(axis=1, columns= 'VIN', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:21.573070Z",
     "start_time": "2024-03-13T00:29:21.565637Z"
    }
   },
   "outputs": [],
   "source": [
    "df['id'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:21.994106Z",
     "start_time": "2024-03-13T00:29:21.603675Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(axis=1, columns= 'id', inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:22.334566Z",
     "start_time": "2024-03-13T00:29:21.995161Z"
    }
   },
   "outputs": [],
   "source": [
    "null_counts = df.isnull().sum()\n",
    "total_rows = len(df)\n",
    "null_percentages = (null_counts / total_rows) * 100\n",
    "\n",
    "# Print the result\n",
    "print(null_percentages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:22.340585Z",
     "start_time": "2024-03-13T00:29:22.335174Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Drive column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:22.351885Z",
     "start_time": "2024-03-13T00:29:22.342092Z"
    }
   },
   "outputs": [],
   "source": [
    "df['drive'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Nan with 4 wheel drive as that is the most common occurange. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:22.374999Z",
     "start_time": "2024-03-13T00:29:22.352421Z"
    }
   },
   "outputs": [],
   "source": [
    "df['drive'].fillna('4wd', inplace=True)\n",
    "df['drive'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:22.383546Z",
     "start_time": "2024-03-13T00:29:22.375571Z"
    }
   },
   "outputs": [],
   "source": [
    "df['size'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop this column as 70% are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:22.735140Z",
     "start_time": "2024-03-13T00:29:22.384423Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(axis=1, columns= 'size', inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:23.057364Z",
     "start_time": "2024-03-13T00:29:22.735830Z"
    }
   },
   "outputs": [],
   "source": [
    "null_counts = df.isnull().sum()\n",
    "total_rows = len(df)\n",
    "null_percentages = (null_counts / total_rows) * 100\n",
    "\n",
    "# Print the result\n",
    "print(null_percentages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:23.080570Z",
     "start_time": "2024-03-13T00:29:23.058077Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df['type'].fillna('sedan', inplace=True)\n",
    "df['type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:23.105914Z",
     "start_time": "2024-03-13T00:29:23.082756Z"
    }
   },
   "outputs": [],
   "source": [
    "df['paint_color'].fillna('white',inplace=True)\n",
    "df['paint_color'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:23.429889Z",
     "start_time": "2024-03-13T00:29:23.106596Z"
    }
   },
   "outputs": [],
   "source": [
    "null_counts = df.isnull().sum()\n",
    "total_rows = len(df)\n",
    "null_percentages = (null_counts / total_rows) * 100\n",
    "\n",
    "# Print the result\n",
    "print(null_percentages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:23.852879Z",
     "start_time": "2024-03-13T00:29:23.430527Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:24.151544Z",
     "start_time": "2024-03-13T00:29:23.853497Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:24.328905Z",
     "start_time": "2024-03-13T00:29:24.152256Z"
    }
   },
   "outputs": [],
   "source": [
    "df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:24.534235Z",
     "start_time": "2024-03-13T00:29:24.329539Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:24.690740Z",
     "start_time": "2024-03-13T00:29:24.534972Z"
    }
   },
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No duplicates in the data and No  Nulls it looks clean to the next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:24.694409Z",
     "start_time": "2024-03-13T00:29:24.691567Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets check the unique columns in ech column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:24.729402Z",
     "start_time": "2024-03-13T00:29:24.695278Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets analyze the data now as initial cleaning is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:24.861961Z",
     "start_time": "2024-03-13T00:29:24.730081Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.nunique()\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:24.864032Z",
     "start_time": "2024-03-13T00:29:24.862610Z"
    }
   },
   "outputs": [],
   "source": [
    "#importing plotly to vialualize the data \n",
    "import plotly.express as px \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:25.213690Z",
     "start_time": "2024-03-13T00:29:24.864615Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x=\"region\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### there seems to be no out liers in the region column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:25.339005Z",
     "start_time": "2024-03-13T00:29:25.214655Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.box(df, x=\"price\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There seems to be some outliers here, need to explore more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['price'].sort_values(ascending=False)\n",
    "df = df.query('price < 55000')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:25.510456Z",
     "start_time": "2024-03-13T00:29:25.375044Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.box(df, x=\"price\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have a more meaningful data now as we have excluced the outliers in price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:25.637248Z",
     "start_time": "2024-03-13T00:29:25.511329Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x=\"price\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:25.785415Z",
     "start_time": "2024-03-13T00:29:25.638062Z"
    }
   },
   "outputs": [],
   "source": [
    "#df['price'].sort_values(ascending=False)\n",
    "df = df.query('price > 1000')\n",
    "fig = px.histogram(df, x=\"price\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:25.982326Z",
     "start_time": "2024-03-13T00:29:25.786299Z"
    }
   },
   "outputs": [],
   "source": [
    "px.histogram(df,x='year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us explore categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:26.210200Z",
     "start_time": "2024-03-13T00:29:25.990584Z"
    }
   },
   "outputs": [],
   "source": [
    "#fig = px.histogram(df, x=['manufacturer'], marginal='rug', barmode='overlay')\n",
    "#fig.show()\n",
    "\n",
    "df['manufacturer'].value_counts().plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:26.230589Z",
     "start_time": "2024-03-13T00:29:26.210974Z"
    }
   },
   "outputs": [],
   "source": [
    "#fig = px.histogram(df, x=['model'], marginal='rug', barmode='overlay')\n",
    "#fig.show()\n",
    "\n",
    "df['model'].nunique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:26.252692Z",
     "start_time": "2024-03-13T00:29:26.231148Z"
    }
   },
   "outputs": [],
   "source": [
    "df['model'].value_counts().head(250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given the huge number of models lets try and reduce the models with more marking any thing less then 250 occurances as other. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:26.543220Z",
     "start_time": "2024-03-13T00:29:26.253297Z"
    }
   },
   "outputs": [],
   "source": [
    "first_250_values = df['model'].value_counts().index[:250].tolist()\n",
    "\n",
    "# Create a new column where values not in the first 100 are grouped into a single category\n",
    "df['model'] = df['model'].apply(lambda x: x if x in first_250_values else 'Other')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:26.556957Z",
     "start_time": "2024-03-13T00:29:26.543936Z"
    }
   },
   "outputs": [],
   "source": [
    "df['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:27.126679Z",
     "start_time": "2024-03-13T00:29:26.557753Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x=['condition'], marginal='rug', barmode='overlay')\n",
    "fig.show()\n",
    "\n",
    "#Categorical columns \n",
    "\n",
    "# condition        object\n",
    "# cylinders        object\n",
    "# fuel             object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cylinders'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:27.368282Z",
     "start_time": "2024-03-13T00:29:27.140289Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T17:52:00.250169Z",
     "start_time": "2024-03-13T17:52:00.220136Z"
    }
   },
   "outputs": [],
   "source": [
    "numerical_columns = df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# Select categorical columns\n",
    "categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(\"Numerical columns:\", numerical_columns)\n",
    "print(\"Categorical columns:\", categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:27.434719Z",
     "start_time": "2024-03-13T00:29:27.423284Z"
    }
   },
   "outputs": [],
   "source": [
    "df['drive'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:27.447789Z",
     "start_time": "2024-03-13T00:29:27.435317Z"
    }
   },
   "outputs": [],
   "source": [
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:27.460434Z",
     "start_time": "2024-03-13T00:29:27.448471Z"
    }
   },
   "outputs": [],
   "source": [
    "df['paint_color'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:27.472450Z",
     "start_time": "2024-03-13T00:29:27.461072Z"
    }
   },
   "outputs": [],
   "source": [
    "df['transmission'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:27.482613Z",
     "start_time": "2024-03-13T00:29:27.473145Z"
    }
   },
   "outputs": [],
   "source": [
    "df['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:27.495229Z",
     "start_time": "2024-03-13T00:29:27.483293Z"
    }
   },
   "outputs": [],
   "source": [
    "df['transmission'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:27.574844Z",
     "start_time": "2024-03-13T00:29:27.495825Z"
    }
   },
   "outputs": [],
   "source": [
    "df['fuel'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we have looked at all the categorical and numerical features and cleaned them as necessary let us explore the relationship of these features to price which we want to predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:29.105333Z",
     "start_time": "2024-03-13T00:29:27.575863Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for feature in numerical_columns:\n",
    "    plt.subplot(3, 5, numerical_columns.index(feature) + 1)\n",
    "    sns.histplot(data=df[feature], bins=50, kde=True)\n",
    "    plt.title(feature)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There seem to be some odometer outliers, we need to take care of them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:29.236265Z",
     "start_time": "2024-03-13T00:29:29.106042Z"
    }
   },
   "outputs": [],
   "source": [
    "df['odometer'].sort_values(ascending=False).plot(kind='box')\n",
    "\n",
    "percentage_over_40000 = (len(df[df['odometer'] > 400000]))\n",
    "print(percentage_over_40000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These 655 cars have reading over 250000 which is creating issues with our distribution so we will remove it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:29.267232Z",
     "start_time": "2024-03-13T00:29:29.239507Z"
    }
   },
   "outputs": [],
   "source": [
    "df =  df[df['odometer'] <= 250000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:30.758051Z",
     "start_time": "2024-03-13T00:29:29.267828Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "for feature in numerical_columns:\n",
    "    plt.subplot(3, 5, numerical_columns.index(feature) + 1)\n",
    "    sns.histplot(data=df[feature], bins=50, kde=True)\n",
    "    plt.title(feature)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:30.985219Z",
     "start_time": "2024-03-13T00:29:30.758769Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets exp[lore the relation of categorical   features to price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:30.988164Z",
     "start_time": "2024-03-13T00:29:30.985901Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:36.308433Z",
     "start_time": "2024-03-13T00:29:30.988829Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(20, 9))\n",
    "axes = axes.ravel()  # Flatten the 2D array of axes\n",
    "\n",
    "# Loop through each categorical column\n",
    "for i, column in enumerate(categorical_columns):\n",
    "    sns.countplot(x=df[column], data=df, palette='bright', ax=axes[i], saturation=0.95)\n",
    "    for container in axes[i].containers:\n",
    "        axes[i].bar_label(container, color='black', size=10)\n",
    "    axes[i].set_title(f'Count Plot of {column.capitalize()}')\n",
    "    axes[i].set_xlabel(column.capitalize())\n",
    "    axes[i].set_ylabel('Count')\n",
    "\n",
    "# Adjust layout and show plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to take a look at region manufacturer and state and region "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:29:36.318646Z",
     "start_time": "2024-03-13T00:29:36.309150Z"
    }
   },
   "outputs": [],
   "source": [
    "df['region'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i am going to drop the region column as I think itds not very well corelated with price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:30:05.861051Z",
     "start_time": "2024-03-13T00:30:05.825716Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop('region', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T00:31:27.285766Z",
     "start_time": "2024-03-13T00:31:27.272945Z"
    }
   },
   "outputs": [],
   "source": [
    "df['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns.remove('region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T10:28:32.560883Z",
     "start_time": "2024-03-14T10:28:28.723208Z"
    }
   },
   "outputs": [],
   "source": [
    "# Categorical Feature vs. Price\n",
    "plt.figure(figsize=(40, 30))\n",
    "for feature in categorical_columns:\n",
    "#    print (categorical_columns.index(feature)+1)\n",
    "    plt.subplot(3, 4, categorical_columns.index(feature)+1)\n",
    "    sns.boxplot(data=df, x=feature, y='price')\n",
    "    plt.title(f'{feature} vs. Price')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:44:29.276408Z",
     "start_time": "2024-03-13T19:44:28.438666Z"
    }
   },
   "outputs": [],
   "source": [
    "# Categorical Feature vs. Price\n",
    "plt.figure(figsize=(30, 20))\n",
    "for feature in numerical_columns:\n",
    "    plt.subplot(3, 3, numerical_columns.index(feature) + 1)\n",
    "    sns.scatterplot(data=df, x=feature, y='price')\n",
    "    plt.title(f'{feature} vs. Price')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T17:59:21.457894Z",
     "start_time": "2024-03-13T17:59:21.341979Z"
    }
   },
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "correlation_matrix = df[numerical_columns].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation After our initial exploration and fine tuning of the business understanding, it is time to construct our final dataset prior to modeling.  Here, we want to make sure to handle any integrity issues and cleaning, the engineering of new features, any transformations that we believe should happen (scaling, logarithms, normalization, etc.), and general preparation for modeling with `sklearn`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries for transformation and modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:58:09.153533Z",
     "start_time": "2024-03-15T02:58:09.151784Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into test and train sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:20:21.072380Z",
     "start_time": "2024-03-15T02:20:20.950566Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.3,random_state = 42)\n",
    "\n",
    "X_test.info() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With your (almost?) final dataset in hand, it is now time to build some models.  Here, you should build a number of different regression models with the price as the target.  In building your models, you should explore different parameters and be sure to cross-validate your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we have split the data lets us write some pre processors to process the data which will be used in the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T19:11:18.527748Z",
     "start_time": "2024-03-16T19:11:18.523949Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "categorical_features = ['manufacturer', 'condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'type', 'paint_color']\n",
    "numerical_features = ['year', 'odometer']\n",
    "print ( categorical_features, numerical_features)\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (OneHotEncoder(), categorical_features),\n",
    "    (StandardScaler(), numerical_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:56:49.308607Z",
     "start_time": "2024-03-15T02:56:49.306783Z"
    }
   },
   "outputs": [],
   "source": [
    "linear_pipe = Pipeline([('preprocessor', preprocessor),('model',LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:56:55.640585Z",
     "start_time": "2024-03-15T02:56:55.638765Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {'model__fit_intercept': [True, False]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:58:32.528766Z",
     "start_time": "2024-03-15T02:58:22.403312Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(linear_pipe, param_grid = param_grid, cv = 5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T02:58:42.446209Z",
     "start_time": "2024-03-15T02:58:42.444123Z"
    }
   },
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best R-squared score (on training data):\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets explore the test score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model =  grid_search.best_estimator_\n",
    "test_score  = best_model.score(X_test,y_test)\n",
    "print(\"Test score:\", test_score)\n",
    "type(best_model)\n",
    "\n",
    "# intercept = best_model.intercept_\n",
    "# coefficients = best_model.coef_  # Returns an array of coefficients\n",
    "\n",
    "\n",
    "model_step = best_model.named_steps['model']  # Assuming 'model' is your model's name in the pipeline \n",
    "coefficients = model_step.coef_\n",
    "intercept = model_step.intercept_\n",
    "\n",
    "print(coefficients , \"  \", intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T03:22:06.962507Z",
     "start_time": "2024-03-15T03:22:06.960169Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = best_model.named_steps['preprocessor']\n",
    "transformed_feature_names = preprocessor.get_feature_names_out()\n",
    "all_feature_names = ['intercept'] + transformed_feature_names.tolist()\n",
    "coefficients_df = pd.DataFrame({'Feature': all_feature_names, 'Coefficient': [intercept] + coefficients.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T03:27:14.627179Z",
     "start_time": "2024-03-15T03:27:14.624914Z"
    }
   },
   "outputs": [],
   "source": [
    "coefficients_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "encoded_matrix = preprocessor.transform(X_train)\n",
    "# Permutation Importance (Calculates importance with encoded features)\n",
    "result = permutation_importance(model_step, encoded_matrix.toarray() , y_train, n_repeats=10)\n",
    "feature_importances = result.importances_mean\n",
    "\n",
    "# Get original feature names\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Print Results\n",
    "for name, importance in zip(feature_names, feature_importances):\n",
    "    print(f\"Feature: {name}, Importance: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us plot this data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T14:53:00.394914Z",
     "start_time": "2024-03-15T14:52:58.358929Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Sort by importance\n",
    "df = df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(20, 80))\n",
    "plt.barh(df['Feature'], df['Importance'], color='skyblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Permutation Importance')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to display most important on top\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the above we can see that The odometer and year are the main contributirs to the price followed by fuel type diesel and 8 cylinder vehicles. This is giving us a good idea of what affects the price. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since there is not much use for the manufacturer and the model columns we will use the Sequential feature selection to limit the number of parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T19:33:33.394781Z",
     "start_time": "2024-03-16T19:31:48.678602Z"
    }
   },
   "outputs": [],
   "source": [
    "## We are importing libraries to feature selection \n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "param_grid = {'selector__n_features_to_select': [10]}\n",
    "\n",
    "linear_pipe = Pipeline([('preprocessor', preprocessor),\n",
    "                        ('selector', SequentialFeatureSelector(LinearRegression()) ), \n",
    "                        ('model', LinearRegression())])\n",
    "                                                        \n",
    "grid_search = GridSearchCV(linear_pipe, param_grid=param_grid, cv=5).fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "print(\"Best R-squared score (on training data):\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T19:15:36.193888Z",
     "start_time": "2024-03-16T19:15:36.190840Z"
    }
   },
   "outputs": [],
   "source": [
    "## retriving the best model \n",
    "best_model =  grid_search.best_estimator_\n",
    "model_step = best_model.named_steps['model']\n",
    "selector = best_model.named_steps['selector']\n",
    "coefficients = model_step.coef_\n",
    "intercept = model_step.intercept_\n",
    "\n",
    "preprocessor = best_model.named_steps['preprocessor']\n",
    "selector_step = best_model.named_steps['selector']\n",
    "selected_features_mask = selector_step.get_support()\n",
    "\n",
    "# Examining the coeffients\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "selected_feature_names = [name for name, selected in zip(feature_names, selected_features_mask) if selected]\n",
    "print(selected_feature_names)\n",
    "print(\"Coefficients:\", coefficients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets us now move on ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T19:17:48.420140Z",
     "start_time": "2024-03-16T19:16:13.100972Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import  Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "ridge_param_dict = {'ridge__alpha':np.logspace(0, 10, 50)}\n",
    "\n",
    "ridge_pipe = Pipeline([('preprocessor', preprocessor),\n",
    "                                     ('ridge', Ridge())])\n",
    "\n",
    "ridge_grid = GridSearchCV(estimator = ridge_pipe,\n",
    "                          param_grid = ridge_param_dict,\n",
    "                          scoring = \"neg_mean_squared_error\")\n",
    "\n",
    "ridge_grid.fit(X_train,y_train)\n",
    "\n",
    "train_preds = ridge_grid.best_estimator_.predict(X_train)\n",
    "test_preds = ridge_grid.best_estimator_.predict(X_test)\n",
    "\n",
    "ridge_train_mse = mean_squared_error(train_preds,y_train)\n",
    "ridge_test_mse = mean_squared_error(test_preds,y_test)\n",
    "\n",
    "\n",
    "print(f'Train MSE: {ridge_train_mse}')\n",
    "print(f'Test MSE: {ridge_test_mse}')\n",
    "ridge_pipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will add Lasso Regression to the mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T19:31:48.677637Z",
     "start_time": "2024-03-16T19:18:16.186503Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "param_grid = {'model__alpha':[0.0001, 0.001, 0.01, 0.1, 1.0, 10]} \n",
    "\n",
    "laso_pipe = Pipeline([('preprocessor', preprocessor),\n",
    "                      ('model', Lasso())])\n",
    "\n",
    "lasso_grid = GridSearchCV(laso_pipe, param_grid = param_grid,cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "lasso_grid.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems like Lasso regressor is unable to converge to a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "With some modeling accomplished, we aim to reflect on what we identify as a high quality model and what we are able to learn from this.  We should review our business objective and explore how well we can provide meaningful insight on drivers of used car prices.  Your goal now is to distill your findings and determine whether the earlier phases need revisitation and adjustment or if you have information of value to bring back to your client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upon Running a few algorithms it is clear that odometer and model year parameters are a big drive of the used car prices. Since the large dimentioanl space some of our regression algorithms are unable to converge or complete grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T19:34:44.677297Z",
     "start_time": "2024-03-16T19:34:35.867087Z"
    }
   },
   "outputs": [],
   "source": [
    "## Lets add poly features to the numeric data so we can see if the accuracy or Linearregression improves that that is best score as of now.\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "categorical_features = ['manufacturer', 'condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive',\n",
    "                        'type', 'paint_color']\n",
    "numerical_features = ['year', 'odometer']\n",
    "print(categorical_features, numerical_features)\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (OneHotEncoder(), categorical_features),\n",
    "   ( PolynomialFeatures(degree=3, include_bias=False),numerical_features ),\n",
    "    (StandardScaler(), numerical_features)\n",
    ")\n",
    "linear_pipe = Pipeline([('preprocessor', preprocessor), ('model', LinearRegression())])\n",
    "param_grid = {'model__fit_intercept': [True, False]}\n",
    "grid_search = GridSearchCV(linear_pipe, param_grid=param_grid, cv=5).fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best R-squared score (on training data):\", best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "Now that we've settled on our models and findings, it is time to deliver the information to the client.  You should organize your work as a basic report that details your primary findings.  Keep in mind that your audience is a group of used car dealers interested in fine tuning their inventory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have analyzed the data and after the modeling we see that LinearRegression with most of the features gives the best result in our model comparision.\n",
    "The take away for the used car dealers is that the most significant factors affecting the prices of the car is Year and Odometer reading, as the year increase the prices of the car decreases and as the odometer reading increases the price of the car also decreases. There are other factors like Number of cylinders and front sheel drive vehice also affect the price of the used cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
